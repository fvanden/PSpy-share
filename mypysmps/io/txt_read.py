# -*- coding: utf-8 -*-
#################
import os

import numpy as np
import pandas as pd
import csv
from csv import reader
from copy import deepcopy

from ..core.smps import ParticleSizer
from ..config import get_instrument_header
from .csv_read import read_aim_csv, read_opc_csv
from .read_aux import grimm_file_to_config
#################

"""
mysmps.io.txt_read
==================

Functions for reading of csv files:
    read_aim_txt
    read_opc_txt

Created on Thu Jul 24 11:22 2020

@author: flovan / fvanden

Revision history:   24.07.2020 - Created
                    14.09.2020 - read_opc_txt added
                    11.08.2022 - read_grimm_txt added


"""

def read_aim_txt(filename, fileorg = 'AIM', **kwargs):
    """
    Reads SMPS data from a text file generated by AIM software
    
    Parameters
    ----------
    filename : str
        path and name of file to read
        
    fileorg : str
        different file organisations can be found in the default_config
        for new filetypes add mappings here and specify the filetype
        
    kwargs : 
        metadata, dict : user defined metadata - DEFAULT: taken from file
        header, list : user defined header - DEFAULT: taken from file
        delimiter, str : user defined delimiter - DEFAULT: taken from file
        
    Returns
    -------
    smps : smps
        mysmps.core.smps object
    """
    # rename file into csv file
    
    pre, ext = os.path.splitext(filename)
    newfilename = pre + '.csv'
    os.rename(filename, newfilename)    
    
    # pass to csv reader
    
    SMPS = read_aim_csv(newfilename, fileorg, encoding = 'iso8859_15', **kwargs)
    
    return SMPS

def read_opc_txt(filename, fileorg = 'OPC', **kwargs):
    """
    Reads OPC data from a text file 
    
    Parameters
    ----------
    filename : str
        path and name of file to read
        
    fileorg : str
        different file organisations can be found in the default_config
        for new filetypes add mappings here and specify the filetype
        
    kwargs : 
        metadata, dict : user defined metadata - DEFAULT: taken from file
        header, list : user defined header - DEFAULT: taken from mypysmps.default_config file
        delimiter, str : user defined delimiter - DEFAULT: taken from file
        
    Returns
    -------
    smps : smps
        mysmps.core.smps object
    """
    # rename file into csv file
    
    pre, ext = os.path.splitext(filename)
    newfilename = pre + '.csv'
    os.rename(filename, newfilename)    
    
    # pass to csv reader
    
    SMPS = read_opc_csv(newfilename, fileorg, encoding = 'iso8859_15', **kwargs)
    
    return SMPS

def read_grimm_txt(filename, fileorg = 'Grimm', **kwargs):
    """
    Reads Grimm data from a text file 
    
    Parameters
    ----------
    filename : str
        path and name of file to read
        
    fileorg : str
        different file organisations can be found in the default_config
        for new filetypes add mappings here and specify the filetype
        
    kwargs : 
        metadata, dict : user defined metadata - DEFAULT: taken from file
        header, list : user defined header - DEFAULT: taken from mypysmps.default_config file
        delimiter, str : user defined delimiter - DEFAULT: taken from file
        
    Returns
    -------
    smps : smps
        mysmps.core.smps object
    """   

    # get header from config, if given in kwargs, it will be overwritten
    # if not in INSTRUMENT_HEADERS in default config file, header from file 
    # instrument file will be used

    header = deepcopy(get_instrument_header(fileorg))

    imetadata = kwargs.get("metadata", None)
    header = kwargs.get("header", header)
    delimiter = kwargs.get("delimiter", ',')

    metadata = {}
    data = []

    start = False
    with open(filename) as text_file:
        text_reader = text_file.readlines()
        line_count = 0
        while line_count < 20:
            for row in text_reader:
                line_count += 1
                if start is True:
                    try:
                        arow = row.split(delimiter)
                        arow[-1] = arow[-1].strip('\n')
                        data.append(arow)
                    except:
                        pass
                elif 'DateTime' in row:
                    if header is None:
                        header = row.split(delimiter)
                        header[-1] = header[-1].strip('\n')
                    start = True
                else:
                    metadata.update({'file header': row.strip('\n')})
                    
    # organise data in dict
    datadict = {}
    for hname in header:
        datadict[hname] = []
    for row in range(0,len(data)):
        for column in range(0,len(data[row])):
            datadict[header[column]].append(data[row][column])
            
    if imetadata:
        metadata.update(imetadata)

    # sort and organise variables

    time, sample, data, diameter, outdict = grimm_file_to_config(datadict, metadata, header)

    #return time, sample, data, diameter, outdict

    return ParticleSizer(time, sample, data, diameter, metadata, header, instrument_type = fileorg, **outdict)
